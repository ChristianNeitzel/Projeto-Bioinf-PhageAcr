{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, roc_curve, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set \t Shape of X_train: (1570, 25) \n",
      "\t\t Shape of y_train: (1570,) \n",
      "\n",
      "Validation Set \t Shape of X_val: (225, 25) \n",
      "\t\t Shape of y_val: (225,) \n",
      "\n",
      "Test Set \t Shape of X_test: (449, 25) \n",
      "\t\t Shape of y_test: (449,)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('PhageAcr_ML_dataset_cdhit.csv')       # Read dataset\n",
    "df.set_index('ID', inplace=True)                        # Set the \"ID\" column as the index\n",
    "df = df.rename(columns={'Protein Acr': 'Protein_Acr'})  # Renaming columns to avoid issues later\n",
    "\n",
    "# Extracting features (X) and target variable (y)\n",
    "X = df.drop('Protein_Acr', axis=1)    # Keep only the features in variable x\n",
    "y = df['Protein_Acr']                 # Assign our Target variable as y\n",
    "\n",
    "# Split the dataset into training+validation (80%) and test sets (20%)\n",
    "X_temp, X_test, y_temp, y_test = train_test_split(X, y, test_size=0.2, random_state=42)   # random_state will allow for the reproductibility of the split\n",
    "\n",
    "# Split the training+validation set into training (70%) and validation sets (10% of the original data)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_temp, y_temp, test_size=0.125, random_state=42)\n",
    "\n",
    "# Checking the shape of the resulting sets\n",
    "print(f'Training Set \\t Shape of X_train: {X_train.shape} \\n\\t\\t Shape of y_train: {y_train.shape} \\n')\n",
    "print(f'Validation Set \\t Shape of X_val: {X_val.shape} \\n\\t\\t Shape of y_val: {y_val.shape} \\n')\n",
    "print(f'Test Set \\t Shape of X_test: {X_test.shape} \\n\\t\\t Shape of y_test: {y_test.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning for Decision Tree:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define the hyperparameters grid for Decision Tree\n",
    "param_grid_dt = {\n",
    "    'max_depth': [3, 5, 7, 9],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "# Initialize GridSearchCV for Decision Tree\n",
    "grid_search_dt = GridSearchCV(dt_model, param_grid_dt, cv=5, scoring='accuracy')\n",
    "\n",
    "# Perform GridSearchCV\n",
    "grid_search_dt.fit(X_train, y_train)\n",
    "\n",
    "# Get the best hyperparameters\n",
    "best_params_dt = grid_search_dt.best_params_\n",
    "\n",
    "# Initialize Decision Tree classifier with best hyperparameters\n",
    "best_dt_model = DecisionTreeClassifier(random_state=42, **best_params_dt)\n",
    "\n",
    "# Train the Decision Tree classifier with best hyperparameters\n",
    "best_dt_model.fit(X_train, y_train)\n",
    "\n",
    "## VALIDATION SET\n",
    "# Make predictions on the validation set\n",
    "y_val_pred_dt_tuned = best_dt_model.predict(X_val)\n",
    "\n",
    "# Calculate evaluation metrics for the validation set\n",
    "val_accuracy_dt_tuned = accuracy_score(y_val, y_val_pred_dt_tuned)\n",
    "val_precision_dt_tuned = precision_score(y_val, y_val_pred_dt_tuned)\n",
    "val_recall_dt_tuned = recall_score(y_val, y_val_pred_dt_tuned)\n",
    "val_f1_dt_tuned = f1_score(y_val, y_val_pred_dt_tuned)\n",
    "\n",
    "# Print the evaluation metrics for tuned Decision Tree and compare with the original metrics\n",
    "print(\"Decision Tree Validation Set Default Parameters vs Hyperparameter Tuning (CD-HIT) \\n\")\n",
    "df_metrics_dt_val_tuned = pd.DataFrame({\n",
    "    \"Parameters\": [\"Default\", \"Tuned\"],\n",
    "    \"Accuracy\": [val_accuracy_dt, val_accuracy_dt_tuned], \n",
    "    \"Precision\": [val_precision_dt, val_precision_dt_tuned], \n",
    "    \"Recall\": [val_recall_dt, val_recall_dt_tuned], \n",
    "    \"F1-Score\": [val_f1_dt, val_f1_dt_tuned]\n",
    "}).round(2)\n",
    "\n",
    "print(df_metrics_dt_val_tuned, \"\\n\\n\")\n",
    "\n",
    "## TEST SET\n",
    "# Make predictions on the test set\n",
    "y_test_pred_dt_tuned = best_dt_model.predict(X_test)\n",
    "\n",
    "# Calculate evaluation metrics for the test set\n",
    "test_accuracy_dt_tuned = accuracy_score(y_test, y_test_pred_dt_tuned)\n",
    "test_precision_dt_tuned = precision_score(y_test, y_test_pred_dt_tuned)\n",
    "test_recall_dt_tuned = recall_score(y_test, y_test_pred_dt_tuned)\n",
    "test_f1_dt_tuned = f1_score(y_test, y_test_pred_dt_tuned)\n",
    "\n",
    "# Print the evaluation metrics for tuned Decision Tree and compare with the original metrics\n",
    "print(\"Decision Tree Test Set Default Parameters vs Hyperparameter Tuning (CD-HIT) \\n\")\n",
    "df_metrics_dt_test_tuned = pd.DataFrame({\n",
    "    \"Parameters\": [\"Default\", \"Tuned\"],\n",
    "    \"Accuracy\": [test_accuracy_dt, test_accuracy_dt_tuned], \n",
    "    \"Precision\": [test_precision_dt, test_precision_dt_tuned], \n",
    "    \"Recall\": [test_recall_dt, test_recall_dt_tuned], \n",
    "    \"F1-Score\": [test_f1_dt, test_f1_dt_tuned]\n",
    "}).round(2)\n",
    "\n",
    "print(df_metrics_dt_test_tuned)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning for RandomForest:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest Validation Set Default Parameters vs Hyperparameter Tuning (CD-HIT) \n",
      "\n",
      "  Parameters  Accuracy  Precision  Recall  F1-Score\n",
      "0    Default      0.89       0.80    0.98      0.88\n",
      "1      Tuned      0.91       0.81    0.99      0.89 \n",
      "\n",
      "\n",
      "RandomForest Test Set Default Parameters vs Hyperparameter Tuning (CD-HIT) \n",
      "\n",
      "  Parameters  Accuracy  Precision  Recall  F1-Score\n",
      "0    Default      0.94       0.90    0.97      0.94\n",
      "1      Tuned      0.93       0.89    0.97      0.93\n"
     ]
    }
   ],
   "source": [
    "# Define the hyperparameters grid for RandomForest\n",
    "param_grid_rf = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [None, 10, 20],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "# Initialize GridSearchCV for RandomForest\n",
    "grid_search_rf = GridSearchCV(rf_model, param_grid_rf, cv=5, scoring='accuracy')\n",
    "\n",
    "# Perform GridSearchCV\n",
    "grid_search_rf.fit(X_train, y_train)\n",
    "\n",
    "# Get the best hyperparameters\n",
    "best_params_rf = grid_search_rf.best_params_\n",
    "\n",
    "# Initialize RandomForest classifier with best hyperparameters\n",
    "best_rf_model = RandomForestClassifier(random_state=42, **best_params_rf)\n",
    "\n",
    "# Train the RandomForest classifier with best hyperparameters\n",
    "best_rf_model.fit(X_train, y_train)\n",
    "\n",
    "## VALIDATION SET\n",
    "# Make predictions on the validation set\n",
    "y_val_pred_rf_tuned = best_rf_model.predict(X_val)\n",
    "\n",
    "# Calculate evaluation metrics for the validation set\n",
    "val_accuracy_rf_tuned = accuracy_score(y_val, y_val_pred_rf_tuned)\n",
    "val_precision_rf_tuned = precision_score(y_val, y_val_pred_rf_tuned)\n",
    "val_recall_rf_tuned = recall_score(y_val, y_val_pred_rf_tuned)\n",
    "val_f1_rf_tuned = f1_score(y_val, y_val_pred_rf_tuned)\n",
    "\n",
    "# Print the evaluation metrics for tuned Random Forest and compare with the original metrics\n",
    "print(\"RandomForest Validation Set Default Parameters vs Hyperparameter Tuning (CD-HIT) \\n\")\n",
    "df_metrics_rf_val_tuned = pd.DataFrame({\n",
    "    \"Parameters\": [\"Default\", \"Tuned\"],\n",
    "    \"Accuracy\": [val_accuracy_rf, val_accuracy_rf_tuned], \n",
    "    \"Precision\": [val_precision_rf, val_precision_rf_tuned], \n",
    "    \"Recall\": [val_recall_rf, val_recall_rf_tuned], \n",
    "    \"F1-Score\": [val_f1_rf, val_f1_rf_tuned]\n",
    "}).round(2)\n",
    "\n",
    "print(df_metrics_rf_val_tuned, \"\\n\\n\")\n",
    "\n",
    "## TEST SET\n",
    "# Make predictions on the test set\n",
    "y_test_pred_rf_tuned = best_rf_model.predict(X_test)\n",
    "\n",
    "# Calculate evaluation metrics for the test set\n",
    "test_accuracy_rf_tuned = accuracy_score(y_test, y_test_pred_rf_tuned)\n",
    "test_precision_rf_tuned = precision_score(y_test, y_test_pred_rf_tuned)\n",
    "test_recall_rf_tuned = recall_score(y_test, y_test_pred_rf_tuned)\n",
    "test_f1_rf_tuned = f1_score(y_test, y_test_pred_rf_tuned)\n",
    "\n",
    "# Print the evaluation metrics for tuned Random Forest and compare with the original metrics\n",
    "print(\"RandomForest Test Set Default Parameters vs Hyperparameter Tuning (CD-HIT) \\n\")\n",
    "df_metrics_rf_test_tuned = pd.DataFrame({\n",
    "    \"Parameters\": [\"Default\", \"Tuned\"],\n",
    "    \"Accuracy\": [test_accuracy_rf, test_accuracy_rf_tuned], \n",
    "    \"Precision\": [test_precision_rf, test_precision_rf_tuned], \n",
    "    \"Recall\": [test_recall_rf, test_recall_rf_tuned], \n",
    "    \"F1-Score\": [test_f1_rf, test_f1_rf_tuned]\n",
    "}).round(2)\n",
    "\n",
    "print(df_metrics_rf_test_tuned)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning for SVM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 25 candidates, totalling 125 fits\n",
      "[CV 1/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.516 total time=   0.1s\n",
      "[CV 2/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.516 total time=   0.1s\n",
      "[CV 3/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.516 total time=   0.1s\n",
      "[CV 4/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.513 total time=   0.1s\n",
      "[CV 5/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.513 total time=   0.1s\n",
      "[CV 1/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.516 total time=   0.1s\n",
      "[CV 2/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.516 total time=   0.1s\n",
      "[CV 3/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.516 total time=   0.1s\n",
      "[CV 4/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.513 total time=   0.1s\n",
      "[CV 5/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.513 total time=   0.1s\n",
      "[CV 1/5] END .....C=0.1, gamma=0.01, kernel=rbf;, score=0.516 total time=   0.1s\n",
      "[CV 2/5] END .....C=0.1, gamma=0.01, kernel=rbf;, score=0.516 total time=   0.1s\n",
      "[CV 3/5] END .....C=0.1, gamma=0.01, kernel=rbf;, score=0.516 total time=   0.1s\n",
      "[CV 4/5] END .....C=0.1, gamma=0.01, kernel=rbf;, score=0.513 total time=   0.1s\n",
      "[CV 5/5] END .....C=0.1, gamma=0.01, kernel=rbf;, score=0.513 total time=   0.1s\n",
      "[CV 1/5] END ....C=0.1, gamma=0.001, kernel=rbf;, score=0.516 total time=   0.1s\n",
      "[CV 2/5] END ....C=0.1, gamma=0.001, kernel=rbf;, score=0.516 total time=   0.1s\n",
      "[CV 3/5] END ....C=0.1, gamma=0.001, kernel=rbf;, score=0.516 total time=   0.1s\n",
      "[CV 4/5] END ....C=0.1, gamma=0.001, kernel=rbf;, score=0.513 total time=   0.1s\n",
      "[CV 5/5] END ....C=0.1, gamma=0.001, kernel=rbf;, score=0.513 total time=   0.1s\n",
      "[CV 1/5] END ...C=0.1, gamma=0.0001, kernel=rbf;, score=0.516 total time=   0.1s\n",
      "[CV 2/5] END ...C=0.1, gamma=0.0001, kernel=rbf;, score=0.516 total time=   0.0s\n",
      "[CV 3/5] END ...C=0.1, gamma=0.0001, kernel=rbf;, score=0.516 total time=   0.1s\n",
      "[CV 4/5] END ...C=0.1, gamma=0.0001, kernel=rbf;, score=0.513 total time=   0.1s\n",
      "[CV 5/5] END ...C=0.1, gamma=0.0001, kernel=rbf;, score=0.513 total time=   0.1s\n",
      "[CV 1/5] END ..........C=1, gamma=1, kernel=rbf;, score=0.516 total time=   0.1s\n",
      "[CV 2/5] END ..........C=1, gamma=1, kernel=rbf;, score=0.516 total time=   0.1s\n",
      "[CV 3/5] END ..........C=1, gamma=1, kernel=rbf;, score=0.516 total time=   0.1s\n",
      "[CV 4/5] END ..........C=1, gamma=1, kernel=rbf;, score=0.513 total time=   0.1s\n",
      "[CV 5/5] END ..........C=1, gamma=1, kernel=rbf;, score=0.513 total time=   0.1s\n",
      "[CV 1/5] END ........C=1, gamma=0.1, kernel=rbf;, score=0.516 total time=   0.1s\n",
      "[CV 2/5] END ........C=1, gamma=0.1, kernel=rbf;, score=0.516 total time=   0.1s\n",
      "[CV 3/5] END ........C=1, gamma=0.1, kernel=rbf;, score=0.516 total time=   0.1s\n",
      "[CV 4/5] END ........C=1, gamma=0.1, kernel=rbf;, score=0.513 total time=   0.1s\n",
      "[CV 5/5] END ........C=1, gamma=0.1, kernel=rbf;, score=0.513 total time=   0.1s\n",
      "[CV 1/5] END .......C=1, gamma=0.01, kernel=rbf;, score=0.519 total time=   0.1s\n",
      "[CV 2/5] END .......C=1, gamma=0.01, kernel=rbf;, score=0.519 total time=   0.1s\n",
      "[CV 3/5] END .......C=1, gamma=0.01, kernel=rbf;, score=0.519 total time=   0.1s\n",
      "[CV 4/5] END .......C=1, gamma=0.01, kernel=rbf;, score=0.516 total time=   0.1s\n",
      "[CV 5/5] END .......C=1, gamma=0.01, kernel=rbf;, score=0.513 total time=   0.1s\n",
      "[CV 1/5] END ......C=1, gamma=0.001, kernel=rbf;, score=0.516 total time=   0.1s\n",
      "[CV 2/5] END ......C=1, gamma=0.001, kernel=rbf;, score=0.519 total time=   0.1s\n",
      "[CV 3/5] END ......C=1, gamma=0.001, kernel=rbf;, score=0.522 total time=   0.1s\n",
      "[CV 4/5] END ......C=1, gamma=0.001, kernel=rbf;, score=0.519 total time=   0.1s\n",
      "[CV 5/5] END ......C=1, gamma=0.001, kernel=rbf;, score=0.519 total time=   0.1s\n",
      "[CV 1/5] END .....C=1, gamma=0.0001, kernel=rbf;, score=0.653 total time=   0.1s\n",
      "[CV 2/5] END .....C=1, gamma=0.0001, kernel=rbf;, score=0.697 total time=   0.1s\n",
      "[CV 3/5] END .....C=1, gamma=0.0001, kernel=rbf;, score=0.634 total time=   0.1s\n",
      "[CV 4/5] END .....C=1, gamma=0.0001, kernel=rbf;, score=0.688 total time=   0.1s\n",
      "[CV 5/5] END .....C=1, gamma=0.0001, kernel=rbf;, score=0.675 total time=   0.1s\n",
      "[CV 1/5] END .........C=10, gamma=1, kernel=rbf;, score=0.516 total time=   0.1s\n",
      "[CV 2/5] END .........C=10, gamma=1, kernel=rbf;, score=0.516 total time=   0.1s\n",
      "[CV 3/5] END .........C=10, gamma=1, kernel=rbf;, score=0.516 total time=   0.1s\n",
      "[CV 4/5] END .........C=10, gamma=1, kernel=rbf;, score=0.513 total time=   0.1s\n",
      "[CV 5/5] END .........C=10, gamma=1, kernel=rbf;, score=0.513 total time=   0.1s\n",
      "[CV 1/5] END .......C=10, gamma=0.1, kernel=rbf;, score=0.516 total time=   0.1s\n",
      "[CV 2/5] END .......C=10, gamma=0.1, kernel=rbf;, score=0.516 total time=   0.1s\n",
      "[CV 3/5] END .......C=10, gamma=0.1, kernel=rbf;, score=0.516 total time=   0.1s\n",
      "[CV 4/5] END .......C=10, gamma=0.1, kernel=rbf;, score=0.513 total time=   0.1s\n",
      "[CV 5/5] END .......C=10, gamma=0.1, kernel=rbf;, score=0.513 total time=   0.1s\n",
      "[CV 1/5] END ......C=10, gamma=0.01, kernel=rbf;, score=0.519 total time=   0.1s\n",
      "[CV 2/5] END ......C=10, gamma=0.01, kernel=rbf;, score=0.519 total time=   0.1s\n",
      "[CV 3/5] END ......C=10, gamma=0.01, kernel=rbf;, score=0.519 total time=   0.1s\n",
      "[CV 4/5] END ......C=10, gamma=0.01, kernel=rbf;, score=0.516 total time=   0.1s\n",
      "[CV 5/5] END ......C=10, gamma=0.01, kernel=rbf;, score=0.513 total time=   0.1s\n",
      "[CV 1/5] END .....C=10, gamma=0.001, kernel=rbf;, score=0.519 total time=   0.1s\n",
      "[CV 2/5] END .....C=10, gamma=0.001, kernel=rbf;, score=0.519 total time=   0.1s\n",
      "[CV 3/5] END .....C=10, gamma=0.001, kernel=rbf;, score=0.525 total time=   0.1s\n",
      "[CV 4/5] END .....C=10, gamma=0.001, kernel=rbf;, score=0.519 total time=   0.1s\n",
      "[CV 5/5] END .....C=10, gamma=0.001, kernel=rbf;, score=0.516 total time=   0.1s\n",
      "[CV 1/5] END ....C=10, gamma=0.0001, kernel=rbf;, score=0.666 total time=   0.1s\n",
      "[CV 2/5] END ....C=10, gamma=0.0001, kernel=rbf;, score=0.701 total time=   0.1s\n",
      "[CV 3/5] END ....C=10, gamma=0.0001, kernel=rbf;, score=0.643 total time=   0.1s\n",
      "[CV 4/5] END ....C=10, gamma=0.0001, kernel=rbf;, score=0.688 total time=   0.1s\n",
      "[CV 5/5] END ....C=10, gamma=0.0001, kernel=rbf;, score=0.685 total time=   0.1s\n",
      "[CV 1/5] END ........C=100, gamma=1, kernel=rbf;, score=0.516 total time=   0.1s\n",
      "[CV 2/5] END ........C=100, gamma=1, kernel=rbf;, score=0.516 total time=   0.1s\n",
      "[CV 3/5] END ........C=100, gamma=1, kernel=rbf;, score=0.516 total time=   0.1s\n",
      "[CV 4/5] END ........C=100, gamma=1, kernel=rbf;, score=0.513 total time=   0.1s\n",
      "[CV 5/5] END ........C=100, gamma=1, kernel=rbf;, score=0.513 total time=   0.1s\n",
      "[CV 1/5] END ......C=100, gamma=0.1, kernel=rbf;, score=0.516 total time=   0.1s\n",
      "[CV 2/5] END ......C=100, gamma=0.1, kernel=rbf;, score=0.516 total time=   0.1s\n",
      "[CV 3/5] END ......C=100, gamma=0.1, kernel=rbf;, score=0.516 total time=   0.1s\n",
      "[CV 4/5] END ......C=100, gamma=0.1, kernel=rbf;, score=0.513 total time=   0.1s\n",
      "[CV 5/5] END ......C=100, gamma=0.1, kernel=rbf;, score=0.513 total time=   0.1s\n",
      "[CV 1/5] END .....C=100, gamma=0.01, kernel=rbf;, score=0.519 total time=   0.1s\n",
      "[CV 2/5] END .....C=100, gamma=0.01, kernel=rbf;, score=0.519 total time=   0.1s\n",
      "[CV 3/5] END .....C=100, gamma=0.01, kernel=rbf;, score=0.519 total time=   0.1s\n",
      "[CV 4/5] END .....C=100, gamma=0.01, kernel=rbf;, score=0.516 total time=   0.1s\n",
      "[CV 5/5] END .....C=100, gamma=0.01, kernel=rbf;, score=0.513 total time=   0.1s\n",
      "[CV 1/5] END ....C=100, gamma=0.001, kernel=rbf;, score=0.519 total time=   0.1s\n",
      "[CV 2/5] END ....C=100, gamma=0.001, kernel=rbf;, score=0.519 total time=   0.1s\n",
      "[CV 3/5] END ....C=100, gamma=0.001, kernel=rbf;, score=0.525 total time=   0.1s\n",
      "[CV 4/5] END ....C=100, gamma=0.001, kernel=rbf;, score=0.519 total time=   0.1s\n",
      "[CV 5/5] END ....C=100, gamma=0.001, kernel=rbf;, score=0.516 total time=   0.1s\n",
      "[CV 1/5] END ...C=100, gamma=0.0001, kernel=rbf;, score=0.666 total time=   0.1s\n",
      "[CV 2/5] END ...C=100, gamma=0.0001, kernel=rbf;, score=0.701 total time=   0.1s\n",
      "[CV 3/5] END ...C=100, gamma=0.0001, kernel=rbf;, score=0.643 total time=   0.0s\n",
      "[CV 4/5] END ...C=100, gamma=0.0001, kernel=rbf;, score=0.691 total time=   0.1s\n",
      "[CV 5/5] END ...C=100, gamma=0.0001, kernel=rbf;, score=0.685 total time=   0.1s\n",
      "[CV 1/5] END .......C=1000, gamma=1, kernel=rbf;, score=0.516 total time=   0.1s\n",
      "[CV 2/5] END .......C=1000, gamma=1, kernel=rbf;, score=0.516 total time=   0.1s\n",
      "[CV 3/5] END .......C=1000, gamma=1, kernel=rbf;, score=0.516 total time=   0.1s\n",
      "[CV 4/5] END .......C=1000, gamma=1, kernel=rbf;, score=0.513 total time=   0.1s\n",
      "[CV 5/5] END .......C=1000, gamma=1, kernel=rbf;, score=0.513 total time=   0.1s\n",
      "[CV 1/5] END .....C=1000, gamma=0.1, kernel=rbf;, score=0.516 total time=   0.1s\n",
      "[CV 2/5] END .....C=1000, gamma=0.1, kernel=rbf;, score=0.516 total time=   0.1s\n",
      "[CV 3/5] END .....C=1000, gamma=0.1, kernel=rbf;, score=0.516 total time=   0.1s\n",
      "[CV 4/5] END .....C=1000, gamma=0.1, kernel=rbf;, score=0.513 total time=   0.1s\n",
      "[CV 5/5] END .....C=1000, gamma=0.1, kernel=rbf;, score=0.513 total time=   0.1s\n",
      "[CV 1/5] END ....C=1000, gamma=0.01, kernel=rbf;, score=0.519 total time=   0.1s\n",
      "[CV 2/5] END ....C=1000, gamma=0.01, kernel=rbf;, score=0.519 total time=   0.1s\n",
      "[CV 3/5] END ....C=1000, gamma=0.01, kernel=rbf;, score=0.519 total time=   0.1s\n",
      "[CV 4/5] END ....C=1000, gamma=0.01, kernel=rbf;, score=0.516 total time=   0.1s\n",
      "[CV 5/5] END ....C=1000, gamma=0.01, kernel=rbf;, score=0.513 total time=   0.1s\n",
      "[CV 1/5] END ...C=1000, gamma=0.001, kernel=rbf;, score=0.519 total time=   0.1s\n",
      "[CV 2/5] END ...C=1000, gamma=0.001, kernel=rbf;, score=0.519 total time=   0.1s\n",
      "[CV 3/5] END ...C=1000, gamma=0.001, kernel=rbf;, score=0.525 total time=   0.1s\n",
      "[CV 4/5] END ...C=1000, gamma=0.001, kernel=rbf;, score=0.519 total time=   0.1s\n",
      "[CV 5/5] END ...C=1000, gamma=0.001, kernel=rbf;, score=0.516 total time=   0.1s\n",
      "[CV 1/5] END ..C=1000, gamma=0.0001, kernel=rbf;, score=0.666 total time=   0.1s\n",
      "[CV 2/5] END ..C=1000, gamma=0.0001, kernel=rbf;, score=0.701 total time=   0.1s\n",
      "[CV 3/5] END ..C=1000, gamma=0.0001, kernel=rbf;, score=0.643 total time=   0.1s\n",
      "[CV 4/5] END ..C=1000, gamma=0.0001, kernel=rbf;, score=0.691 total time=   0.1s\n",
      "[CV 5/5] END ..C=1000, gamma=0.0001, kernel=rbf;, score=0.685 total time=   0.1s\n",
      "{'C': 100, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "SVC(C=100, gamma=0.0001, random_state=42)\n",
      "SVM Validation Set Default Parameters vs Hyperparameter Tuning (CD-HIT) \n",
      "\n",
      "  Parameters  Accuracy  Precision  Recall  F1-Score\n",
      "0    Default      0.80       0.66    1.00      0.80\n",
      "1      Tuned      0.79       0.88    0.55      0.68 \n",
      "\n",
      "\n",
      "SVM Test Set Default Parameters vs Hyperparameter Tuning (CD-HIT) \n",
      "\n",
      "  Parameters  Accuracy  Precision  Recall  F1-Score\n",
      "0    Default      0.85       0.78    0.99      0.87\n",
      "1      Tuned      0.71       0.94    0.46      0.62\n"
     ]
    }
   ],
   "source": [
    "# Define the hyperparameters grid for SVM\n",
    "param_grid_svm = {\n",
    "    'C': [0.1, 1, 10, 100, 1000],                   \n",
    "    'gamma': [1, 0.1, 0.01, 0.001, 0.0001],         \n",
    "    'kernel': ['rbf']                            # Other Kernels: 'linear', 'rbf', 'poly' and 'sigmoid'; to note: only 'rbf' provides actual results for this dataset\n",
    "}\n",
    "\n",
    "# Initialize GridSearchCV for SVM\n",
    "grid_search_svm = GridSearchCV(svm_model, param_grid_svm, refit = True, verbose = 3) \n",
    "\n",
    "# Perform GridSearchCV\n",
    "grid_search_svm.fit(X_train, y_train)\n",
    "\n",
    "# Get the best hyperparameters\n",
    "best_params_svm = grid_search_svm.best_params_\n",
    "print(best_params_svm)\n",
    "\n",
    "# Initialize SVM with best hyperparameters\n",
    "best_svm_model = grid_search_svm.best_estimator_\n",
    "print(best_svm_model)\n",
    "\n",
    "# Train SVM with best hyperparameters\n",
    "best_svm_model.fit(X_train, y_train)\n",
    "\n",
    "## VALIDATION SET\n",
    "# Make predictions on the validation set\n",
    "y_val_pred_svm_tuned = best_svm_model.predict(X_val)\n",
    "\n",
    "# Calculate evaluation metrics for the validation set\n",
    "val_accuracy_svm_tuned = accuracy_score(y_val, y_val_pred_svm_tuned)\n",
    "val_precision_svm_tuned = precision_score(y_val, y_val_pred_svm_tuned)\n",
    "val_recall_svm_tuned = recall_score(y_val, y_val_pred_svm_tuned)\n",
    "val_f1_svm_tuned = f1_score(y_val, y_val_pred_svm_tuned)\n",
    "\n",
    "# Print the evaluation metrics for tuned Random Forest and compare with the original metrics\n",
    "print(\"SVM Validation Set Default Parameters vs Hyperparameter Tuning (CD-HIT) \\n\")\n",
    "df_metrics_svm_val_tuned = pd.DataFrame({\n",
    "    \"Parameters\": [\"Default\", \"Tuned\"],\n",
    "    \"Accuracy\": [val_accuracy_svm, val_accuracy_svm_tuned], \n",
    "    \"Precision\": [val_precision_svm, val_precision_svm_tuned], \n",
    "    \"Recall\": [val_recall_svm, val_recall_svm_tuned], \n",
    "    \"F1-Score\": [val_f1_svm, val_f1_svm_tuned]\n",
    "}).round(2)\n",
    "\n",
    "print(df_metrics_svm_val_tuned, \"\\n\\n\")\n",
    "\n",
    "## TEST SET\n",
    "# Make predictions on the test set\n",
    "y_test_pred_svm_tuned = best_svm_model.predict(X_test)\n",
    "\n",
    "# Calculate evaluation metrics for the test set\n",
    "test_accuracy_svm_tuned = accuracy_score(y_test, y_test_pred_svm_tuned)\n",
    "test_precision_svm_tuned = precision_score(y_test, y_test_pred_svm_tuned)\n",
    "test_recall_svm_tuned = recall_score(y_test, y_test_pred_svm_tuned)\n",
    "test_f1_svm_tuned = f1_score(y_test, y_test_pred_svm_tuned)\n",
    "\n",
    "# Print the evaluation metrics for tuned Random Forest and compare with the original metrics\n",
    "print(\"SVM Test Set Default Parameters vs Hyperparameter Tuning (CD-HIT) \\n\")\n",
    "df_metrics_svm_test_tuned = pd.DataFrame({\n",
    "    \"Parameters\": [\"Default\", \"Tuned\"],\n",
    "    \"Accuracy\": [test_accuracy_svm, test_accuracy_svm_tuned], \n",
    "    \"Precision\": [test_precision_svm, test_precision_svm_tuned], \n",
    "    \"Recall\": [test_recall_svm, test_recall_svm_tuned], \n",
    "    \"F1-Score\": [test_f1_svm, test_f1_svm_tuned]\n",
    "}).round(2)\n",
    "\n",
    "print(df_metrics_svm_test_tuned)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning for XGBoost:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Validation Set Default Parameters vs Hyperparameter Tuning (CD-HIT) \n",
      "\n",
      "  Parameters  Accuracy  Precision  Recall  F1-Score\n",
      "0    Default      0.90       0.82    0.97      0.89\n",
      "1      Tuned      0.91       0.83    0.97      0.89 \n",
      "\n",
      "\n",
      "XGBoost Test Set Default Parameters vs Hyperparameter Tuning (CD-HIT) \n",
      "\n",
      "  Parameters  Accuracy  Precision  Recall  F1-Score\n",
      "0    Default      0.92       0.90    0.95      0.92\n",
      "1      Tuned      0.92       0.89    0.96      0.92\n"
     ]
    }
   ],
   "source": [
    "# Define the hyperparameters grid for XGBoost\n",
    "param_grid_xgb = {\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'learning_rate': [0.1, 0.01, 0.001],\n",
    "    'n_estimators': [100, 200, 300]\n",
    "}\n",
    "\n",
    "# Initialize GridSearchCV for XGBoost\n",
    "grid_search_xgb = GridSearchCV(xgb.XGBClassifier(objective='binary:logistic', eval_metric='logloss'), param_grid_xgb, cv=5, scoring='accuracy')\n",
    "\n",
    "# Perform GridSearchCV\n",
    "grid_search_xgb.fit(X_train, y_train)\n",
    "\n",
    "# Get the best hyperparameters\n",
    "best_params_xgb = grid_search_xgb.best_params_\n",
    "\n",
    "# Initialize XGBoost classifier with best hyperparameters\n",
    "best_xgb_model = xgb.XGBClassifier(objective='binary:logistic', eval_metric='logloss', **best_params_xgb)\n",
    "\n",
    "# Train the XGBoost classifier with best hyperparameters\n",
    "best_xgb_model.fit(X_train, y_train)\n",
    "\n",
    "## VALIDATION SET\n",
    "# Make predictions on the validation set\n",
    "y_val_pred_xgb_tuned = best_xgb_model.predict(X_val)\n",
    "\n",
    "# Calculate evaluation metrics for the validation set\n",
    "val_accuracy_xgb_tuned = accuracy_score(y_val, y_val_pred_xgb_tuned)\n",
    "val_precision_xgb_tuned = precision_score(y_val, y_val_pred_xgb_tuned)\n",
    "val_recall_xgb_tuned = recall_score(y_val, y_val_pred_xgb_tuned)\n",
    "val_f1_xgb_tuned = f1_score(y_val, y_val_pred_xgb_tuned)\n",
    "\n",
    "# Print the evaluation metrics for tuned XGBoost and compare with the original metrics\n",
    "print(\"XGBoost Validation Set Default Parameters vs Hyperparameter Tuning (CD-HIT) \\n\")\n",
    "df_metrics_xgb_val_tuned = pd.DataFrame({\n",
    "    \"Parameters\": [\"Default\", \"Tuned\"],\n",
    "    \"Accuracy\": [val_accuracy_xgb, val_accuracy_xgb_tuned], \n",
    "    \"Precision\": [val_precision_xgb, val_precision_xgb_tuned], \n",
    "    \"Recall\": [val_recall_xgb, val_recall_xgb_tuned], \n",
    "    \"F1-Score\": [val_f1_xgb, val_f1_xgb_tuned]\n",
    "}).round(2)\n",
    "\n",
    "print(df_metrics_xgb_val_tuned, \"\\n\\n\")\n",
    "\n",
    "## TEST SET\n",
    "# Make predictions on the test set\n",
    "y_test_pred_xgb_tuned = best_xgb_model.predict(X_test)\n",
    "\n",
    "# Calculate evaluation metrics for the test set\n",
    "test_accuracy_xgb_tuned = accuracy_score(y_test, y_test_pred_xgb_tuned)\n",
    "test_precision_xgb_tuned = precision_score(y_test, y_test_pred_xgb_tuned)\n",
    "test_recall_xgb_tuned = recall_score(y_test, y_test_pred_xgb_tuned)\n",
    "test_f1_xgb_tuned = f1_score(y_test, y_test_pred_xgb_tuned)\n",
    "\n",
    "# Print the evaluation metrics for tuned XGBoost and compare with the original metrics\n",
    "print(\"XGBoost Test Set Default Parameters vs Hyperparameter Tuning (CD-HIT) \\n\")\n",
    "df_metrics_xgb_test_tuned = pd.DataFrame({\n",
    "    \"Parameters\": [\"Default\", \"Tuned\"],\n",
    "    \"Accuracy\": [test_accuracy_xgb, test_accuracy_xgb_tuned], \n",
    "    \"Precision\": [test_precision_xgb, test_precision_xgb_tuned], \n",
    "    \"Recall\": [test_recall_xgb, test_recall_xgb_tuned], \n",
    "    \"F1-Score\": [test_f1_xgb, test_f1_xgb_tuned]\n",
    "}).round(2)\n",
    "\n",
    "print(df_metrics_xgb_test_tuned)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
